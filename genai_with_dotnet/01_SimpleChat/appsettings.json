{
  "SelectedProvider": "GitHub",
  "Providers": {
    "GitHub": {
      "EndpointUrl": "https://models.github.ai/inference",
      "ModelName": "mistral-ai/Ministral-3B",
      "TokenConfigKey": "GitHub:Token"
    },
    "Azure": {
      "EndpointUrl": "https://YOUR-RESOURCE.openai.azure.com",
      "ModelName": "gpt-4",
      "DeploymentName": "gpt-4",
      "TokenConfigKey": "Azure:ApiKey"
    },
    "OpenAI": {
      "ModelName": "gpt-4",
      "TokenConfigKey": "OpenAI:ApiKey"
    },
    "Local": {
      "EndpointUrl": "http://localhost:11434",
      "ModelName": "llama2",
      "TokenConfigKey": ""
    }
  },
  "ChatOptions": {
    "MaxOutputTokens": 300,
    "Temperature": 0.2
  },
  "UI": {
    "WelcomeTitle": "Welcome to AI Chat Assistant (Q&A)",
    "ExitMessage": "Thank you for using AI Chat Assistant. Goodbye! ðŸ‘‹"
  }
}
